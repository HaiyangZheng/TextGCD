2024-12-07 20:37:38,961 - INFO - Training cifar10_test_seed4 with the following settings:
2024-12-07 20:37:38,962 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cifar10_test_seed4
 seed=4
 evaluate=False
 dataset_name=cifar10
 backbone_name=ViT-B/16
 cub_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets/CUB
 cub_retrieved_text_path=retrieved_text/cub_retrieved_text.npy
 flowers_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets
 flowers_retrieved_text_path=retrieved_text/flowers_retrieved_text.npy
 scars_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets
 scars_retrieved_text_path=retrieved_text/scars_retrieved_text.npy
 pets_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets
 pets_retrieved_text_path=retrieved_text/pets_retrieved_text.npy
 cifar10_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets/cifar10
 cifar10_retrieved_text_path=retrieved_text/cifar10_retrieved_text.npy
 cifar100_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets/cifar100
 cifar100_retrieved_text_path=retrieved_text/cifar100_retrieved_text.npy
 imagenet_root=/home/fandral/Nan/NCD_dataset
 imagenet_retrieved_text_path=retrieved_text/imagenet100_retrieved_text.npy
 osr_split_dir=data/ssb_splits
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 use_ssb_splits=True
 transform=imagenet
 n_views=2
 selecting_ratio=0.6
 lambda_loss=0.2
 warm_up_epochs=10
 class_aligning_epochs=5
 num_attributes=2
 num_tags=3
 tau_s=0.1
 tau_u=0.1
 tau_t_start=0.07
 tau_t_end=0.04
 warmup_teacher_temp_epochs=30
 memax_weight=2
 image_size=224
 train_classes=range(0, 5)
 unlabeled_classes=range(5, 10)
 num_labeled_classes=5
 num_unlabeled_classes=5
 log_path=exp/cifar10_test_seed4-2024-12-07-20-37/logs/log.txt
 model_path=exp/cifar10_test_seed4-2024-12-07-20-37/models/model.pth
 device=cuda
2024-12-07 20:37:38,967 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-12-07 20:37:41,372 - INFO - Building custom CLIP
2024-12-07 20:37:42,488 - INFO - Turning off gradients in both the image and the text encoder
2024-12-07 20:37:42,491 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-12-07 20:37:47,476 - INFO - len of train dataset: 50000
2024-12-07 20:37:47,478 - INFO - len of test dataset: 37500
2024-12-07 20:37:47,489 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-12-07 20:37:47,489 - INFO - Selecting 2250 high-confidence samples for co-teaching.
2024-12-07 20:39:32,641 - INFO - Before Train Accuracies: All 0.3549 | Old 0.0432 | New 0.5107
2024-12-07 20:39:32,642 - INFO - Before Train Accuracies: All 0.2665 | Old 0.0086 | New 0.3954
2024-12-07 20:44:46,840 - INFO - Epoch 1/200, Total Loss: 3.5292, Base Loss: 1.4725, Con Loss: 2.0567, Pseudo Loss Image: 0.0000, Pseudo Loss Text: 0.0000
2024-12-07 20:44:46,840 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-12-07 20:44:46,840 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-12-07 20:46:24,985 - INFO - Text classifier Epoch 0 Train Accuracies: All 0.9203 | Old 0.9555 | New 0.9027
2024-12-07 20:46:24,986 - INFO - Image classifier Epoch 0 Train Accuracies: All 0.9507 | Old 0.9294 | New 0.9613
2024-12-07 20:48:03,140 - INFO - Weighted Accuracies: All 0.7299 | Old 0.9746 | New 0.6075
2024-12-07 20:48:03,802 - INFO - Saved model!
2024-12-07 20:53:16,192 - INFO - Epoch 2/200, Total Loss: 2.5110, Base Loss: 0.6324, Con Loss: 1.8785, Pseudo Loss Image: 0.0000, Pseudo Loss Text: 0.0000
2024-12-07 20:53:16,192 - INFO -    Param Group: classifier_head, Learning Rate: 0.1000
2024-12-07 20:53:16,192 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-12-07 20:54:54,333 - INFO - Text classifier Epoch 1 Train Accuracies: All 0.9696 | Old 0.9518 | New 0.9786
2024-12-07 20:54:54,355 - INFO - Image classifier Epoch 1 Train Accuracies: All 0.9448 | Old 0.9282 | New 0.9531
2024-12-07 20:56:32,748 - INFO - Weighted Accuracies: All 0.7407 | Old 0.9789 | New 0.6216
2024-12-07 20:56:33,484 - INFO - Saved model!
2024-12-07 21:01:49,477 - INFO - Epoch 3/200, Total Loss: 2.3851, Base Loss: 0.5763, Con Loss: 1.8087, Pseudo Loss Image: 0.0000, Pseudo Loss Text: 0.0000
2024-12-07 21:01:49,478 - INFO -    Param Group: classifier_head, Learning Rate: 0.0999
2024-12-07 21:01:49,478 - INFO -    Param Group: base_parameters, Learning Rate: 0.0005
2024-12-07 21:03:27,944 - INFO - Text classifier Epoch 2 Train Accuracies: All 0.9698 | Old 0.9443 | New 0.9826
2024-12-07 21:03:27,944 - INFO - Image classifier Epoch 2 Train Accuracies: All 0.9526 | Old 0.9139 | New 0.9719
2024-12-07 21:05:05,796 - INFO - Weighted Accuracies: All 0.6981 | Old 0.9748 | New 0.5598
