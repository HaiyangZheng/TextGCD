2024-12-07 16:37:47,575 - INFO - Training cub_test_seed1 with the following settings:
2024-12-07 16:37:47,576 - INFO - Command-line arguments: output_dir=exp
 experiment_name=cub_test_seed1
 seed=1
 evaluate=False
 dataset_name=cub
 backbone_name=ViT-B/16
 cub_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets/CUB
 cub_retrieved_text_path=retrieved_text/cub_retrieved_text.npy
 flowers_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets
 flowers_retrieved_text_path=retrieved_text/flowers_retrieved_text.npy
 scars_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets
 scars_retrieved_text_path=retrieved_text/scars_retrieved_text.npy
 pets_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets
 pets_retrieved_text_path=retrieved_text/pets_retrieved_text.npy
 cifar10_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets/cifar10
 cifar10_retrieved_text_path=retrieved_text/cifar10_retrieved_text.npy
 cifar100_root=/leonardo_work/IscrC_Fed-GCD/GCD_datasets/cifar100
 cifar100_retrieved_text_path=retrieved_text/cifar100_retrieved_text.npy
 imagenet_root=/home/fandral/Nan/NCD_dataset
 imagenet_retrieved_text_path=retrieved_text/imagenet100_retrieved_text.npy
 osr_split_dir=data/ssb_splits
 epochs=200
 base_lr=0.0005
 classifier_lr=0.1
 momentum=0.9
 weight_decay=0.0001
 num_workers=8
 batch_size=128
 prop_train_labels=0.5
 use_ssb_splits=True
 transform=imagenet
 n_views=2
 selecting_ratio=0.6
 lambda_loss=0.2
 warm_up_epochs=10
 class_aligning_epochs=5
 num_attributes=2
 num_tags=3
 tau_s=0.1
 tau_u=0.05
 tau_t_start=0.035
 tau_t_end=0.02
 warmup_teacher_temp_epochs=30
 memax_weight=2
 image_size=224
 train_classes=[150, 70, 34, 178, 199, 131, 129, 147, 134, 11, 26, 93, 95, 121, 123, 99, 149, 167, 18, 31, 69, 198, 116, 158, 126, 17, 5, 179, 111, 163, 184, 81, 174, 42, 53, 89, 77, 55, 23, 48, 43, 44, 56, 28, 193, 143, 0, 176, 84, 15, 38, 154, 141, 190, 172, 124, 189, 19, 80, 157, 12, 9, 79, 30, 94, 67, 197, 97, 168, 137, 119, 76, 98, 88, 40, 106, 171, 87, 166, 186, 27, 51, 144, 135, 161, 64, 177, 7, 146, 61, 50, 162, 133, 82, 39, 74, 72, 91, 196, 136]
 unlabeled_classes=[29, 110, 3, 8, 13, 58, 142, 25, 145, 63, 59, 65, 24, 140, 120, 32, 114, 107, 160, 130, 118, 101, 115, 128, 117, 71, 156, 112, 36, 122, 104, 102, 90, 125, 152, 195, 132, 83, 22, 192, 153, 175, 191, 155, 49, 194, 73, 66, 170, 151, 169, 96, 103, 37, 181, 127, 78, 21, 10, 164, 62, 2, 183, 85, 45, 60, 92, 185, 20, 159, 173, 148, 1, 57, 113, 165, 52, 109, 14, 4, 180, 6, 182, 68, 33, 108, 46, 35, 75, 188, 187, 100, 47, 105, 41, 86, 16, 54, 139, 138]
 num_labeled_classes=100
 num_unlabeled_classes=100
 log_path=exp/cub_test_seed1-2024-12-07-16-37/logs/log.txt
 model_path=exp/cub_test_seed1-2024-12-07-16-37/models/model.pth
 device=cuda
2024-12-07 16:37:47,579 - INFO - Loading CLIP (backbone: ViT-B/16)
2024-12-07 16:37:49,640 - INFO - Building custom CLIP
2024-12-07 16:37:50,737 - INFO - Turning off gradients in both the image and the text encoder
2024-12-07 16:37:50,738 - INFO - Parameters that require gradients: ['model.text_projection', 'model.visual.proj', 'model.visual.transformer.resblocks.11.attn.in_proj_weight', 'model.visual.transformer.resblocks.11.attn.in_proj_bias', 'model.visual.transformer.resblocks.11.attn.out_proj.weight', 'model.visual.transformer.resblocks.11.attn.out_proj.bias', 'model.visual.transformer.resblocks.11.ln_1.weight', 'model.visual.transformer.resblocks.11.ln_1.bias', 'model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'model.visual.transformer.resblocks.11.ln_2.weight', 'model.visual.transformer.resblocks.11.ln_2.bias', 'model.transformer.resblocks.11.attn.in_proj_weight', 'model.transformer.resblocks.11.attn.in_proj_bias', 'model.transformer.resblocks.11.attn.out_proj.weight', 'model.transformer.resblocks.11.attn.out_proj.bias', 'model.transformer.resblocks.11.ln_1.weight', 'model.transformer.resblocks.11.ln_1.bias', 'model.transformer.resblocks.11.mlp.c_fc.weight', 'model.transformer.resblocks.11.mlp.c_fc.bias', 'model.transformer.resblocks.11.mlp.c_proj.weight', 'model.transformer.resblocks.11.mlp.c_proj.bias', 'model.transformer.resblocks.11.ln_2.weight', 'model.transformer.resblocks.11.ln_2.bias', 'image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-12-07 16:37:53,793 - INFO - len of train dataset: 5994
2024-12-07 16:37:53,793 - INFO - len of test dataset: 4496
2024-12-07 16:37:53,796 - INFO - Parameters in classifier with big lr: ['image_classifier.weight_g', 'image_classifier.weight_v', 'text_classifier.weight_g', 'text_classifier.weight_v']
2024-12-07 16:37:53,797 - INFO - Selecting 13 high-confidence samples for co-teaching.
